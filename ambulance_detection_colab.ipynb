import torch
from ultralytics import YOLO
import cv2
import numpy as np
from PIL import Image
import time
from google.colab import drive
import os

# Mount Google Drive
drive.mount('/content/drive')

# Install required packages
!pip install ultralytics

# Create directories for dataset
!mkdir -p ambulance_dataset/images/train
!mkdir -p ambulance_dataset/images/val
!mkdir -p ambulance_dataset/labels/train
!mkdir -p ambulance_dataset/labels/val

# Download pre-trained YOLOv8 model
!yolo download model=yolov8n.pt

class AmbulanceDetector:
    def __init__(self, model_path):
        self.model = YOLO(model_path)
        self.classes = ['ambulance']
        
    def detect_image(self, image_path, output_path=None):
        # Read image
        image = cv2.imread(image_path)
        results = self.model(image)
        detections = self._process_results(results)
        
        # Draw detections
        output_image = self._draw_detections(image, detections)
        
        # Save or display result
        if output_path:
            cv2.imwrite(output_path, output_image)
        return detections
    
    def detect_video(self, video_path, output_path=None):
        cap = cv2.VideoCapture(video_path)
        
        # Get video properties
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # Initialize video writer if output path is provided
        if output_path:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        frame_count = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            # Process frame
            results = self.model(frame)
            detections = self._process_results(results)
            
            # Draw detections
            output_frame = self._draw_detections(frame, detections)
            
            # Add progress information
            progress = (frame_count / total_frames) * 100
            self._add_progress_info(output_frame, progress, len(detections))
            
            # Display or write frame
            if output_path:
                out.write(output_frame)
            
            frame_count += 1
        
        # Cleanup
        cap.release()
        if output_path:
            out.release()
        cv2.destroyAllWindows()
    
    def _draw_detections(self, frame, detections):
        output_frame = frame.copy()
        for det in detections:
            x1, y1, x2, y2 = map(int, det['bbox'])
            conf = det['confidence']
            
            # Draw filled rectangle with transparency
            overlay = output_frame.copy()
            cv2.rectangle(overlay, (x1, y1), (x2, y2), (0, 255, 0), -1)
            output_frame = cv2.addWeighted(overlay, 0.3, output_frame, 0.7, 0)
            
            # Draw border
            cv2.rectangle(output_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # Add label with confidence
            label = f'Ambulance: {conf:.2f}'
            label_size, baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            y1_label = max(y1, label_size[1])
            
            # Draw label background
            cv2.rectangle(output_frame, 
                        (x1, y1_label - label_size[1] - 10),
                        (x1 + label_size[0], y1_label + baseline - 10), 
                        (0, 255, 0), 
                        cv2.FILLED)
            
            # Draw label text
            cv2.putText(output_frame, 
                       label,
                       (x1, y1_label - 7),
                       cv2.FONT_HERSHEY_SIMPLEX,
                       0.6, 
                       (0, 0, 0),
                       2)
        
        return output_frame
    
    def _add_progress_info(self, frame, progress, num_detections):
        frame_h, frame_w = frame.shape[:2]
        bar_w = int(frame_w * 0.8)
        bar_h = 20
        bar_x = int((frame_w - bar_w) / 2)
        bar_y = frame_h - 40
        
        # Draw background
        cv2.rectangle(frame,
                     (bar_x, bar_y),
                     (bar_x + bar_w, bar_y + bar_h),
                     (0, 0, 0),
                     cv2.FILLED)
        
        # Draw progress
        progress_w = int(bar_w * (progress / 100))
        cv2.rectangle(frame,
                     (bar_x, bar_y),
                     (bar_x + progress_w, bar_y + bar_h),
                     (0, 255, 0),
                     cv2.FILLED)
        
        # Add text
        cv2.putText(frame,
                   f'Progress: {progress:.1f}% | Detections: {num_detections}',
                   (bar_x, bar_y - 10),
                   cv2.FONT_HERSHEY_SIMPLEX,
                   0.6,
                   (255, 255, 255),
                   2)
    
    def _process_results(self, results):
        detections = []
        for r in results:
            boxes = r.boxes
            for box in boxes:
                if box.cls == 0:  # Ambulance class
                    x1, y1, x2, y2 = box.xyxy[0].tolist()
                    confidence = box.conf.item()
                    detections.append({
                        'bbox': [x1, y1, x2, y2],
                        'confidence': confidence
                    })
        return detections

# Training configuration
def train_model():
    # Initialize YOLO model
    model = YOLO('yolov8n.pt')
    
    # Training settings
    model.train(
        data='ambulance_data.yaml',
        epochs=100,
        imgsz=640,
        batch=16,
        name='ambulance_detector',
        patience=50,
        save=True,
        device='0' if torch.cuda.is_available() else 'cpu'
    )

# Example usage
if __name__ == "__main__":
    # First, train the model
    train_model()
    
    # After training, use the trained model
    detector = AmbulanceDetector('runs/detect/ambulance_detector/weights/best.pt')
    
    # Process image
    detector.detect_image('test_image.jpg', 'output_image.jpg')
    
    # Process video
    detector.detect_video('test_video.mp4', 'output_video.mp4')